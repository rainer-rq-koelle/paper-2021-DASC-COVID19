---
title: "Data Preparation"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#install.packages("ggnewscale")

library(tidyverse)
library(lubridate)
library(zoo)
library(patchwork)
library(ggnewscale)

#Reading raw data
## todo: change utility function list_osn_files
source("./R/list_apt_files.R")
```

# Overview

This file serves as a jump pad for the data preparation (and will be updated as we go).
The utility functions introduced read in the data, perform some associations (e.g. country assignment), filter, and save out the flight-by-flight dataset to drive the study for the DASC paper.

Conventions:

* Opensky Network data downloaded from https://zenodo.org/record/4893103#.YNCqukxCSUk
* airports.csv downloaded from www.ourairports.org.
* downloaded data stored in sub-folder **data-raw**
* trimmed/cleaned data saved out to **data**

More to come. tbd!

# Read in OSN Data

```{r}
###Preparatory codes

#If someone needs filters below, here we can control any selective sample
#Filtering Brazilian and European data to reduce the sample (and csv) size
#Currently, those filters are not in use in the code, they are here just in case.
bra_10_apts <- c("SBBR", "SBGR", "SBSP", "SBKP", "SBRJ", "SBGL", "SBCF", "SBSV", "SBPA", "SBCT")
eur_apts <- c("EHAM","LFPG","EGLL","EDDF","EDDM","LEMD","LIRF","LEBL","EGKK","LSZH")
study_airports <- c(bra_10_apts, eur_apts)

###Preparing airport file
#NOTE: the airports.csv file below is the downloaded file from www.ourairports.org.
airports <- read_csv("data-raw/airports.csv") %>% mutate(continent = case_when(is.na(continent) ~ "NA", TRUE ~ continent))

#There are missing airports and too much variables
apt_countries <- airports %>% transmute(ICAO = ident, CTRY = iso_country) %>% add_row(ICAO  = c("SPJC", "YBMC", "LSZM", "YSCH", "EPLB", "K3M3", "VV01", "SC28", "CWF2", "EHDB", "74XA", "HE13"), CTRY  = c("PE", "AU", "FR", "AU", "PL", "US", "VN", "US", "CA", "NL", "US", "EG"))

#If you need to write
#write_csv(apt_countries, "./data/apt_countries.csv")
#apt_countries is ready.

# Associate the regions
a <- airports %>% filter(continent == "EU") %>% select(iso_country) %>% unique()
eur_countries <- a$iso_country
#eur_countries is ready.

```

## Reading the raw data

### Utility function for reading OSN and saving out analytic data

```{r}
#Here I will assign only one month - "202105". If you want to include a full year, just assign year to "2021" or "2020". It works.
#year <- "202105"
# file_names <- list_apt_files(.year = year)
#open_sky <- map_dfr(file_names, read_csv)


# column specification for OSN -----------------------------------
osn_colspec <- cols(
  callsign = col_character(),
  number = col_character(),
  icao24 = col_character(),
  registration = col_character(),
  typecode = col_character(),
  origin = col_character(),
  destination = col_character(),
  firstseen = col_datetime(format = ""),
  lastseen = col_datetime(format = ""),
  day = col_datetime(format = ""),
  latitude_1 = col_double(),
  longitude_1 = col_double(),
  altitude_1 = col_double(),
  latitude_2 = col_double(),
  longitude_2 = col_double(),
  altitude_2 = col_double()
)

#' read_osn_covid
#' 
#' utility function to read one month of OSN covid data
#'
#' @param .fn filename of OSN data file
#' @param .col_spec dplyr column specification for datatype assignment
#'
read_osn_covid <- function(.fn, .col_spec = osn_colspec){
# todo - check filename

# read 
  fb <- read_csv(file = .fn, col_types = .col_spec)
  
# Selecting relevant variables

  fb <- fb %>% 
  transmute( ADEP = origin
            ,ADES = destination
            ,TYPE = as.factor(typecode)
            ,DATE = date(day)
            ,CALL = callsign
            #,ACFT_ID = aircraft_uid    # throws an error in today's data download
            )

return(fb)
}

#-------------- add ADEP/ADES & country
#' append country code to ADEP and ADES
#'
#' @param .ds flight data set with ADEP and ADES
#' @param .apt_countries lookup of ADEP/ADES and country
#'
#' @return appended dataset
#' @export
#'
append_ad_ctry <- function(.ds, .apt_countries = apt_countries){
  # todo - check for valid dataset
  df <- .ds
  #Joining to ADEP
  df <- left_join(df, .apt_countries, by = c("ADEP" = "ICAO")) %>%
    mutate(ADEP_CTRY = CTRY, .keep = "unused", .after = ADEP)
  #Joining to ADES
  df <- left_join(df, .apt_countries, by = c("ADES" = "ICAO")) %>% 
    mutate(ADES_CTRY = CTRY, .keep = "unused", .after = ADES)
  return(df)
}

#------------------ add region
#' Add region to identified ADEP/ADES country
#'
#' @param .ds flight data set with ADEP_CTRY and ADES_CTRY
#'
#' @return appended data set
#' @export
#'
append_region <- function(.ds, .eur_countries = eur_countries){
  # todo check for valid data set
  df <- .ds
  # append region for study
  df <- df %>%
    # ADEP region
    mutate(ADEP_REG = case_when(
                          ADEP_CTRY == "US" ~ "US"
                         ,ADEP_CTRY == "BR" ~ "BR"
                         ,ADEP_CTRY %in% .eur_countries ~ "EU"
                         ,TRUE ~ "Other")
      ,.after = ADEP_CTRY
      ) %>%
    # ADES region
    mutate(ADES_REG = case_when(
                          ADES_CTRY == "US" ~ "US"
                         ,ADES_CTRY == "BR" ~ "BR"
                         ,ADES_CTRY %in% eur_countries ~ "EU"
                         ,TRUE ~ "Other")
      , .after = ADES_CTRY)
  return(df)
}

#---------------- check / describe data set
#' extract meta data for data set
#'
#' @param .ds covid flight data set
#'
#' @return meta dataset
#' @export
#'
extract_meta_osn <- function(.ds){
  # todo: check for valid data set
  df <- .ds 
  # extract useful meta-data
  df <- df %>% 
    mutate(MOF = floor_date(DATE, unit = "month")) %>%
    group_by(MOF) %>%
    summarise( N = n()                         # number of flights in data set
              ,ADEP_NA = sum(is.na(ADEP))      # number of ADEP NA
              ,ADES_NA = sum(is.na(ADES))
              ,TYPE_NA = sum(is.na(TYPE))
              )
  
  return(df)
}

check_and_write_meta <- function(.new_meta, .my_meta = "./data/meta_osn.csv"){
  our_meta <- .my_meta
  # meta file exists
  if(file.exists(our_meta)){
    meta <- read_csv(our_meta, col_types = cols())  # cÃ¶l_types = cols() to silence
    meta <- meta %>% bind_rows(.new_meta)
    # todo -------------- handle multiple run and changes
  }else{
    meta <- .new_meta
  }
  # store meta data
  write_csv(meta, file = our_meta)
}

prep_base_data <- function(.fn = file_names, ...){
ds <- read_osn_covid(.fn)
ds <- ds %>% append_ad_ctry()
ds <- ds %>% append_region()

meta <- extract_meta_osn(ds)
check_and_write_meta(meta)

#------------ daily counts -------------------------------------
daily_count <- ds %>%
  group_by(DATE) %>% summarise(FLTS = n())
check_and_write_meta(daily_count, "./data/daily_osn.csv")
#----------------------------------------------------------------

ds <- ds %>% drop_na()  # drop all ~ assumed to be clean

# write out base data
my_fn <- gsub(pattern = "-raw", replacement = "", x = .fn)
my_fn <- gsub(pattern = "flightlist_", replacement = "base_osn_", x = my_fn)
my_fn <- gsub(pattern = "\\.gz", replacement = "", x = my_fn)
write_csv(ds, file = my_fn)
message(paste0("run completed for ", my_fn))
}
```

## loop over all data

loop deactivated as base data has been saved out and shared across the project team

```{r, eval=FALSE}
# read all files (note adpat function name)
fns <- list_apt_files()

# crunch study data
walk(fns, .f = prep_base_data)
```

# Todo's, observations, etc.

The following is currently kept and not further processed.

## check for some observations

```{}
# Very few NA's - it's safe to drop and factor now
# todo: check what airports have no country association in ourairports.com
# fb2 %>% filter(is.na(ADEP_CTRY)) %>% group_by(ADEP) %>% count() %>% arrange(desc(n))
# A tibble: 11 x 2
# Groups:   ADEP [11]
#    ADEP      n
#    <chr> <int>
#  1 YPEC    128
#  2 EG32     88
#  3 EGZJ     31
#  4 YCPP     26
#  5 KMAN     16
#  6 KX40     15
#  7 CSV8      9
#  8 CARK      8
#  9 LHKK      2
# 10 CLV2      1
# 11 EKVO      1

fb4 <- fb3 %>% drop_na() %>% mutate(ADEP_CTRY = as.factor(ADEP_CTRY), ADES_CTRY = as.factor(ADES_CTRY))

#NOTE: Here we can adjust the European countries that comprises EU region by editing the "eur_countries" vector:
# Currently in european countries: "GB" "AD" "ES" "AL" "XK" "AT" "BA" "BE" "BG" "IS" "BY" "UA" "CH" "CZ" "SK" "DE" "RU" "DK" "HR" "EE" "FI" "GG" "JE" "IM" "NL" "IE" "FO" "LU" "NO" "PL" "PT" "SE" "LV" "LT" "FR" "GR" "HU" "IT" "LI" "SI" "MT" "MC" "RO" "TR" "MD" "MK" "GI" "RS" "ME" "SM" "GE" "VA"

base_dataset <- fb4 %>% mutate(ADEP_REG = as.factor(case_when(ADEP_CTRY == "US" ~ "US",
                                    ADEP_CTRY == "BR" ~ "BR",
                                    ADEP_CTRY %in% eur_countries ~ "EU",
                                    TRUE ~ "Other")), .after = ADEP_CTRY) %>%
                mutate(ADES_REG = as.factor(case_when(ADES_CTRY == "US" ~ "US",
                                    ADES_CTRY == "BR" ~ "BR",
                                    ADES_CTRY %in% eur_countries ~ "EU",
                                    TRUE ~ "Other")), .after = ADES_CTRY)
colSums(is.na(base_dataset))
# No NA's - yaaayy!!
glimpse(base_dataset)
summary(base_dataset)

```

```{r, eval=TRUE, message=FALSE}
#quick peek

base_filenames <- list.files("./data/", pattern = "base_osn_*")
base_fullnames <- c(paste0("./data/", base_filenames))
full_dataset <- map_dfr(base_fullnames, read_csv)

```

```{r}
#quick first look
temp1 <- full_dataset %>% group_by(DATE, ADEP_REG, ADES_REG) %>% summarize(FLIGHTS = n()) %>% mutate(ROUTE = paste(ADEP_REG, ADES_REG, sep = "-"), .keep = "unused")
temp1

temp1 %>% ggplot(aes(x = DATE)) +
  geom_line(aes(y = (FLIGHTS), color = ROUTE))
```

```{r, dpi=480}
#THRESHOLD AT ROLLING QUANTILES PER YEAR
#Please install the "roll" package.
#install.packages("roll")
library(roll)

ds1 <- full_dataset %>% group_by(YR = year(DATE), DATE) %>% summarize(N = n(), .groups = "drop") %>% mutate(THRESHOLD = quantile(N, probs = 0.7))
ds1

ds1 %>% ggplot(aes(x = DATE)) +
  geom_line(aes(y = THRESHOLD)) +
  geom_point(aes(y = N, color = N > THRESHOLD))
```

```{r}
#CHECK WEEKLY DISTRIBUTION
ds2 <- ds1 %>% 
  mutate( WEEK_DAY = wday(DATE, label = TRUE)
         ,W_END    = WEEK_DAY %in% c("Sat", "Sun"))
uplim <- .95
lowlim <- .20

ds2 <- ds2 %>% mutate(MED = roll_quantile(N, width = 7, p = .50, min_obs = 7),
                      UP_THR = roll_quantile(N, width = 180, p = uplim, min_obs = 7),
                      LOW_THR = roll_quantile(N, width = 180, p = lowlim, min_obs = 7))
ds2

ds2 %>% ggplot(aes(x = DATE)) +
  geom_col(aes(y = MED, fill = !(MED < LOW_THR | MED > UP_THR))) +
  geom_line(aes(y = UP_THR), color = "blue") +
  geom_line(aes(y = LOW_THR), color = "red") +
  scale_x_date(limits = c(as.Date("2019-10-01"), as.Date("2020-12-01")), date_breaks = "30 days", date_labels = "%b\n%y") +
  labs(y = "7-day rolling median", x = NULL, fill = "Normal operation?",
       title = "What is normal?",
       subtitle = "Red line - Lower threshold; Blue line - upper threshold",
       caption = "Lower threshold set to 20th percentile of the last 180 days;\nUpper threshold set to 95th percentile of the last 180 days"
)
```

```
# breadcrumb ------------- need to check what this is for --------------------
#ds2 %>% ggplot() +
  geom_freqpoly(aes(x = N, color = W_END))
```

```{r}
us <- full_dataset %>% 
  filter(ADEP_REG == "US" | ADES_REG == "US") %>%
  group_by(YR = year(DATE), DATE) %>% 
  summarize(N = n(), .groups = "drop") 

# static thresholds, x-th percentile rounded to lower integer
pcts   <- c(0.8, 0.6, 0.3, 0.1)
us_ref <- us %>% filter(YR == 2019) %>%
  pull(N) %>% quantile(probs = pcts) %>% floor()

us_ref2 <- us %>% filter(YR == 2019, DATE >= lubridate::ymd("2019-07-01")) %>%
  pull(N) %>% quantile(probs = pcts) %>% floor()

max_N <- max(us$N)
lvls  <- c("First", "Second", "Third", "Fourth", "Fifth")
us <- us %>% 
  mutate( THRES  = cut(N, breaks = c(max_N, us_ref, 0),  labels = lvls)
         ,THRES2 = cut(N, breaks = c(max_N, us_ref2, 0), labels = lvls)
         )
```
```{r}
us %>%
  ggplot(aes(x = DATE)) +
 # geom_line(aes(y = THRES)) +
  geom_point(aes(y = N, color = THRES2)) +
  geom_line(aes(y = N, colour = THRES2, group = 1)) +
  geom_hline(yintercept = c(max_N, us_ref2, 0))
```

```{r}
# comparator levels
uplim  <- .80
lowlim <- .20
slide  <-  60

tmp <- us %>% 
  mutate( N_sm    = roll_quantile(N, width = 7, p = .50)
         ,MED     = roll_quantile(N, width = 14, p = .50, min_obs = 7)
         ,UP_THR  = roll_quantile(N, width = slide, p = uplim,  min_obs = 7)
         ,LOW_THR = roll_quantile(N, width = slide, p = lowlim, min_obs = 7)
         ,LOW_CRIT= LOW_THR >= MED
         ,UP_CRIT = UP_THR  <= MED
         ,STATE   = case_when( !LOW_CRIT & !UP_CRIT ~ "LEVEL"
                              , LOW_CRIT & !UP_CRIT ~ "CRUNCH"
                              ,!LOW_CRIT &  UP_CRIT ~ "RECOV" 
                              ,TRUE ~ "UNKWN")
         ,BAND    = 4000
         ) %>%
  filter(DATE >= lubridate::ymd("2019-10-01"))

###---------Rainer, the "new_scale_colour()" kinda resets the scale, and you can use another one for the next geom_lines. In the example below, I left the legend.position = "bottom" (instead of "NULL"), just to see the colors------###
Glass <- rgb(0, 0, 0, max = 255, alpha = 0, names = "transparent")

ResilienceMovingBands <- tmp %>%
  ggplot() +
  geom_line(aes(x = DATE, y = N), colour = "grey80") +
  geom_line(aes(x = DATE, y = N_sm, colour = THRES2, group = "RQ"), size = 2) +
  geom_line(aes(x = DATE, y = UP_THR), color = "blue") +
  geom_line(aes(x = DATE, y = LOW_THR), color = "red") +
  #geom_line(aes(x = DATE, y = MED), color = "forestgreen", size = 2) +
  #scale_color_brewer(type = "qual") +
  new_scale_colour() +
  geom_line(aes(x = DATE, y = BAND-100, group= "1"), colour = if_else(tmp$LOW_CRIT, "red",Glass), size = 4) +
  geom_line(aes(x = DATE, y = BAND+16000, group= "1"), colour = if_else(tmp$UP_CRIT, "blue", Glass), size = 4) +
  geom_line(aes(x = DATE, y = BAND-4000, group= "1", colour = STATE), size = 10) +
  scale_colour_manual(values = c("darkred", Glass, "darkblue")) +
  theme_minimal() +
  theme(legend.position = "bottom")
ResilienceMovingBands
```


# Airport Level Considerations

top-5 in the whole sample, confirms preference :)

```{r}
full_dataset %>% 
  group_by(ADEP_REG, ADEP) %>% 
  summarise(N = n()) %>% 
  slice_max(order_by = N, n = 5)
```

```{r}
sbgr <- full_dataset %>% filter(ADEP == "SBGR")
```

```{r}
apt_timeline <- function(.df){
  df <- .df %>% group_by(DATE) %>%
    summarise(N_DEP = n()
              ,DEP_DOM = sum(ADEP_CTRY == ADES_CTRY)
              ,DEP_REG = sum(ADEP_REG == ADES_REG))
}

plot_timeline <- function(.df){
  df <- .df %>% 
  mutate(N_DEP_SM = roll_quantile(N_DEP, width = 7, p = .50))

  p <- df %>%  
  ggplot() +
  geom_line(aes(x = DATE, y = N_DEP), colour = "grey60") +
  geom_line(aes(x = DATE, y = N_DEP_SM)) +
  scale_x_date( limits = c(as.Date("2019-10-01"), as.Date("2021-06-01"))
               ,date_breaks = "60 days", date_labels = "%b\n%y") +
  theme_minimal()
  
  return(p)
}

sbgr %>% apt_timeline() %>% plot_timeline()
```

```{r}
sbgr_tl <- sbgr %>% apt_timeline()

sbgr_tl %>%
  ggplot() +
  geom_point(aes(x = DATE, y = DEP_DOM / N_DEP)) +
  theme_minimal()
```
```{r}
dep_vs_domshare <- function(.df){
  p <- .df %>%
  ggplot() +
  geom_point(aes(x = N_DEP, y = DEP_REG / N_DEP, colour = as.factor(year(DATE)))) +
  labs(colour = NULL) + 
  scale_y_continuous(labels = scales::percent_format(accuracy = 1)
                     ,expand = c(0,0)) +
  theme_minimal() +
  theme(legend.position = c(0.8, 0.8))
return(p)
}

sbgr_tl %>% dep_vs_domshare()
```

```{r}
check_apt <- function(.mvts, .apt){
  apt_mvts <- .mvts %>%
    filter(ADEP == .apt) %>% 
    apt_timeline()
  
  p1 <- apt_mvts  %>% plot_timeline()
  p2 <- apt_mvts %>% dep_vs_domshare()
  
  p <- (p1 + labs(subtitle = .apt)) + p2
return(p)
}

full_dataset %>% check_apt("EGLL")
```

```{r}
full_dataset %>% check_apt("EDDF")
```


```{r}
full_dataset %>% check_apt("LFPG")
```



```{r}
full_dataset %>% check_apt("KATL")
```


```{r}
full_dataset %>% check_apt("KORD")
```

```{r}
full_dataset %>% check_apt("KJFK")
```


```{r}
full_dataset %>% check_apt("EHAM")
```

```{r}
full_dataset %>% check_apt("EHAM")
```
